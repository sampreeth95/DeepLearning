{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all necessary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "from random import random\n",
    "import numpy as np\n",
    "from numpy import load\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy import asarray\n",
    "from numpy.random import randint\n",
    "from numpy import cov\n",
    "from numpy import trace\n",
    "from numpy import iscomplexobj\n",
    "from numpy import asarray\n",
    "from numpy import vstack\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.models import Input\n",
    "from keras.layers import Conv2D, Conv2DTranspose, LeakyReLU, Activation, Concatenate\n",
    "from keras.layers import Input, Dense, Add, Dot, Reshape, Flatten, BatchNormalization, Lambda, Softmax, Embedding, Multiply, Add\n",
    "from matplotlib import pyplot\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from time import time\n",
    "import os\n",
    "import functools\n",
    "\n",
    "from scipy.linalg import sqrtm\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.python.ops import array_ops\n",
    "\n",
    "from keras.engine.base_layer import Layer, InputSpec\n",
    "from keras.engine import *\n",
    "from keras.legacy import interfaces\n",
    "from keras import activations\n",
    "from keras import initializers\n",
    "from keras import regularizers\n",
    "from keras import constraints\n",
    "from keras.utils.generic_utils import func_dump\n",
    "from keras.utils.generic_utils import func_load\n",
    "from keras.utils.generic_utils import deserialize_keras_object\n",
    "from keras.utils.generic_utils import has_arg\n",
    "from keras.utils import conv_utils\n",
    "from keras.models import load_model\n",
    "from random import randint, shuffle, uniform\n",
    "import glob\n",
    "import time\n",
    "import warnings\n",
    "from PIL import Image\n",
    "from random import randint, shuffle, uniform\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, ZeroPadding2D, BatchNormalization, Input, Dropout\n",
    "from keras.layers import Conv2DTranspose, Reshape, Activation, Cropping2D, Flatten\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.activations import relu\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Spectral Normalization, Self Attention Gamma Layer functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DenseSN(Dense):\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) >= 2\n",
    "        input_dim = input_shape[-1]\n",
    "        self.kernel = self.add_weight(shape=(input_dim, self.units),\n",
    "                                      initializer=self.kernel_initializer,\n",
    "                                      name='kernel',\n",
    "                                      regularizer=self.kernel_regularizer,\n",
    "                                      constraint=self.kernel_constraint)\n",
    "        if self.use_bias:\n",
    "            self.bias = self.add_weight(shape=(self.units,),\n",
    "                                        initializer=self.bias_initializer,\n",
    "                                        name='bias',\n",
    "                                        regularizer=self.bias_regularizer,\n",
    "                                        constraint=self.bias_constraint)\n",
    "        else:\n",
    "            self.bias = None\n",
    "        self.u = self.add_weight(shape=tuple([1, self.kernel.shape.as_list()[-1]]),\n",
    "                                 initializer=initializers.RandomNormal(0, 1),\n",
    "                                 name='sn',\n",
    "                                 trainable=False)\n",
    "        self.input_spec = InputSpec(min_ndim=2, axes={-1: input_dim})\n",
    "        self.built = True\n",
    "        \n",
    "    def call(self, inputs, training=None):\n",
    "        def _l2normalize(v, eps=1e-12):\n",
    "            return v / (K.sum(v ** 2) ** 0.5 + eps)\n",
    "        def power_iteration(W, u):\n",
    "            _u = u\n",
    "            _v = _l2normalize(K.dot(_u, K.transpose(W)))\n",
    "            _u = _l2normalize(K.dot(_v, W))\n",
    "            return _u, _v\n",
    "        W_shape = self.kernel.shape.as_list()\n",
    "        #Flatten the Tensor\n",
    "        W_reshaped = K.reshape(self.kernel, [-1, W_shape[-1]])\n",
    "        _u, _v = power_iteration(W_reshaped, self.u)\n",
    "        #Calculate Sigma\n",
    "        sigma=K.dot(_v, W_reshaped)\n",
    "        sigma=K.dot(sigma, K.transpose(_u))\n",
    "        #normalize it\n",
    "        W_bar = W_reshaped / sigma\n",
    "        #reshape weight tensor\n",
    "        if training in {0, False}:\n",
    "            W_bar = K.reshape(W_bar, W_shape)\n",
    "        else:\n",
    "            with tf.control_dependencies([self.u.assign(_u)]):\n",
    "                 W_bar = K.reshape(W_bar, W_shape)  \n",
    "        output = K.dot(inputs, W_bar)\n",
    "        if self.use_bias:\n",
    "            output = K.bias_add(output, self.bias, data_format='channels_last')\n",
    "        if self.activation is not None:\n",
    "            output = self.activation(output)\n",
    "        return output \n",
    "        \n",
    "class _ConvSN(Layer):\n",
    "\n",
    "    def __init__(self, rank,\n",
    "                 filters,\n",
    "                 kernel_size,\n",
    "                 strides=1,\n",
    "                 padding='valid',\n",
    "                 data_format=None,\n",
    "                 dilation_rate=1,\n",
    "                 activation=None,\n",
    "                 use_bias=True,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 activity_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 spectral_normalization=True,\n",
    "                 **kwargs):\n",
    "        super(_ConvSN, self).__init__(**kwargs)\n",
    "        self.rank = rank\n",
    "        self.filters = filters\n",
    "        self.kernel_size = conv_utils.normalize_tuple(kernel_size, rank, 'kernel_size')\n",
    "        self.strides = conv_utils.normalize_tuple(strides, rank, 'strides')\n",
    "        self.padding = conv_utils.normalize_padding(padding)\n",
    "        self.data_format = conv_utils.normalize_data_format(data_format)\n",
    "        self.dilation_rate = conv_utils.normalize_tuple(dilation_rate, rank, 'dilation_rate')\n",
    "        self.activation = activations.get(activation)\n",
    "        self.use_bias = use_bias\n",
    "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
    "        self.bias_initializer = initializers.get(bias_initializer)\n",
    "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
    "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
    "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
    "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
    "        self.bias_constraint = constraints.get(bias_constraint)\n",
    "        self.input_spec = InputSpec(ndim=self.rank + 2)\n",
    "        self.spectral_normalization = spectral_normalization\n",
    "        self.u = None\n",
    "        \n",
    "    def _l2normalize(self, v, eps=1e-12):\n",
    "        return v / (K.sum(v ** 2) ** 0.5 + eps)\n",
    "    \n",
    "    def power_iteration(self, u, W):\n",
    "        '''\n",
    "        Accroding the paper, we only need to do power iteration one time.\n",
    "        '''\n",
    "        v = self._l2normalize(K.dot(u, K.transpose(W)))\n",
    "        u = self._l2normalize(K.dot(v, W))\n",
    "        return u, v\n",
    "    def build(self, input_shape):\n",
    "        if self.data_format == 'channels_first':\n",
    "            channel_axis = 1\n",
    "        else:\n",
    "            channel_axis = -1\n",
    "        if input_shape[channel_axis] is None:\n",
    "            raise ValueError('The channel dimension of the inputs '\n",
    "                             'should be defined. Found `None`.')\n",
    "        input_dim = input_shape[channel_axis]\n",
    "        kernel_shape = self.kernel_size + (input_dim, self.filters)\n",
    "\n",
    "        self.kernel = self.add_weight(shape=kernel_shape,\n",
    "                                      initializer=self.kernel_initializer,\n",
    "                                      name='kernel',\n",
    "                                      regularizer=self.kernel_regularizer,\n",
    "                                      constraint=self.kernel_constraint)\n",
    "\n",
    "        #Spectral Normalization\n",
    "        if self.spectral_normalization:\n",
    "            self.u = self.add_weight(shape=tuple([1, self.kernel.shape.as_list()[-1]]),\n",
    "                                     initializer=initializers.RandomNormal(0, 1),\n",
    "                                     name='sn',\n",
    "                                     trainable=False)\n",
    "        \n",
    "        if self.use_bias:\n",
    "            self.bias = self.add_weight(shape=(self.filters,),\n",
    "                                        initializer=self.bias_initializer,\n",
    "                                        name='bias',\n",
    "                                        regularizer=self.bias_regularizer,\n",
    "                                        constraint=self.bias_constraint)\n",
    "        else:\n",
    "            self.bias = None\n",
    "        # Set input spec.\n",
    "        self.input_spec = InputSpec(ndim=self.rank + 2,\n",
    "                                    axes={channel_axis: input_dim})\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs):\n",
    "        def _l2normalize(v, eps=1e-12):\n",
    "            return v / (K.sum(v ** 2) ** 0.5 + eps)\n",
    "        def power_iteration(W, u):\n",
    "            _u = u\n",
    "            _v = _l2normalize(K.dot(_u, K.transpose(W)))\n",
    "            _u = _l2normalize(K.dot(_v, W))\n",
    "            return _u, _v\n",
    "        \n",
    "        if self.spectral_normalization:\n",
    "            W_shape = self.kernel.shape.as_list()\n",
    "            #Flatten the Tensor\n",
    "            W_reshaped = K.reshape(self.kernel, [-1, W_shape[-1]])\n",
    "            _u, _v = power_iteration(W_reshaped, self.u)\n",
    "            #Calculate Sigma\n",
    "            sigma=K.dot(_v, W_reshaped)\n",
    "            sigma=K.dot(sigma, K.transpose(_u))\n",
    "            #normalize it\n",
    "            W_bar = W_reshaped / sigma\n",
    "            #reshape weight tensor\n",
    "            if training in {0, False}:\n",
    "                W_bar = K.reshape(W_bar, W_shape)\n",
    "            else:\n",
    "                with tf.control_dependencies([self.u.assign(_u)]):\n",
    "                    W_bar = K.reshape(W_bar, W_shape)\n",
    "\n",
    "            #update weitht\n",
    "            self.kernel = W_bar\n",
    "        \n",
    "        if self.rank == 1:\n",
    "            outputs = K.conv1d(\n",
    "                inputs,\n",
    "                self.kernel,\n",
    "                strides=self.strides[0],\n",
    "                padding=self.padding,\n",
    "                data_format=self.data_format,\n",
    "                dilation_rate=self.dilation_rate[0])\n",
    "        if self.rank == 2:\n",
    "            outputs = K.conv2d(\n",
    "                inputs,\n",
    "                self.kernel,\n",
    "                strides=self.strides,\n",
    "                padding=self.padding,\n",
    "                data_format=self.data_format,\n",
    "                dilation_rate=self.dilation_rate)\n",
    "        if self.rank == 3:\n",
    "            outputs = K.conv3d(\n",
    "                inputs,\n",
    "                self.kernel,\n",
    "                strides=self.strides,\n",
    "                padding=self.padding,\n",
    "                data_format=self.data_format,\n",
    "                dilation_rate=self.dilation_rate)\n",
    "\n",
    "        if self.use_bias:\n",
    "            outputs = K.bias_add(\n",
    "                outputs,\n",
    "                self.bias,\n",
    "                data_format=self.data_format)\n",
    "\n",
    "        if self.activation is not None:\n",
    "            return self.activation(outputs)\n",
    "        return outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.data_format == 'channels_last':\n",
    "            space = input_shape[1:-1]\n",
    "            new_space = []\n",
    "            for i in range(len(space)):\n",
    "                new_dim = conv_utils.conv_output_length(\n",
    "                    space[i],\n",
    "                    self.kernel_size[i],\n",
    "                    padding=self.padding,\n",
    "                    stride=self.strides[i],\n",
    "                    dilation=self.dilation_rate[i])\n",
    "                new_space.append(new_dim)\n",
    "            return (input_shape[0],) + tuple(new_space) + (self.filters,)\n",
    "        if self.data_format == 'channels_first':\n",
    "            space = input_shape[2:]\n",
    "            new_space = []\n",
    "            for i in range(len(space)):\n",
    "                new_dim = conv_utils.conv_output_length(\n",
    "                    space[i],\n",
    "                    self.kernel_size[i],\n",
    "                    padding=self.padding,\n",
    "                    stride=self.strides[i],\n",
    "                    dilation=self.dilation_rate[i])\n",
    "                new_space.append(new_dim)\n",
    "            return (input_shape[0], self.filters) + tuple(new_space)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'rank': self.rank,\n",
    "            'filters': self.filters,\n",
    "            'kernel_size': self.kernel_size,\n",
    "            'strides': self.strides,\n",
    "            'padding': self.padding,\n",
    "            'data_format': self.data_format,\n",
    "            'dilation_rate': self.dilation_rate,\n",
    "            'activation': activations.serialize(self.activation),\n",
    "            'use_bias': self.use_bias,\n",
    "            'kernel_initializer': initializers.serialize(self.kernel_initializer),\n",
    "            'bias_initializer': initializers.serialize(self.bias_initializer),\n",
    "            'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n",
    "            'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n",
    "            'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n",
    "            'kernel_constraint': constraints.serialize(self.kernel_constraint),\n",
    "            'bias_constraint': constraints.serialize(self.bias_constraint)\n",
    "        }\n",
    "        base_config = super(_Conv, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "    \n",
    "class ConvSN2D(Conv2D):\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if self.data_format == 'channels_first':\n",
    "            channel_axis = 1\n",
    "        else:\n",
    "            channel_axis = -1\n",
    "        if input_shape[channel_axis] is None:\n",
    "            raise ValueError('The channel dimension of the inputs '\n",
    "                             'should be defined. Found `None`.')\n",
    "        input_dim = input_shape[channel_axis]\n",
    "        kernel_shape = self.kernel_size + (input_dim, self.filters)\n",
    "\n",
    "        self.kernel = self.add_weight(shape=kernel_shape,\n",
    "                                      initializer=self.kernel_initializer,\n",
    "                                      name='kernel',\n",
    "                                      regularizer=self.kernel_regularizer,\n",
    "                                      constraint=self.kernel_constraint)\n",
    "\n",
    "        if self.use_bias:\n",
    "            self.bias = self.add_weight(shape=(self.filters,),\n",
    "                                        initializer=self.bias_initializer,\n",
    "                                        name='bias',\n",
    "                                        regularizer=self.bias_regularizer,\n",
    "                                        constraint=self.bias_constraint)\n",
    "        else:\n",
    "            self.bias = None\n",
    "            \n",
    "        self.u = self.add_weight(shape=tuple([1, self.kernel.shape.as_list()[-1]]),\n",
    "                         initializer=initializers.RandomNormal(0, 1),\n",
    "                         name='sn',\n",
    "                         trainable=False)\n",
    "        \n",
    "      \n",
    "        \n",
    "        # Set input spec.\n",
    "        self.input_spec = InputSpec(ndim=self.rank + 2,\n",
    "                                    axes={channel_axis: input_dim})\n",
    "        self.built = True\n",
    "    def call(self, inputs, training=None):\n",
    "        def _l2normalize(v, eps=1e-12):\n",
    "            return v / (K.sum(v ** 2) ** 0.5 + eps)\n",
    "        def power_iteration(W, u):\n",
    "            #Accroding the paper, we only need to do power iteration one time.\n",
    "            _u = u\n",
    "            _v = _l2normalize(K.dot(_u, K.transpose(W)))\n",
    "            _u = _l2normalize(K.dot(_v, W))\n",
    "            return _u, _v\n",
    "        #Spectral Normalization\n",
    "        W_shape = self.kernel.shape.as_list()\n",
    "        #Flatten the Tensor\n",
    "        W_reshaped = K.reshape(self.kernel, [-1, W_shape[-1]])\n",
    "        _u, _v = power_iteration(W_reshaped, self.u)\n",
    "        #Calculate Sigma\n",
    "        sigma=K.dot(_v, W_reshaped)\n",
    "        sigma=K.dot(sigma, K.transpose(_u))\n",
    "        #normalize it\n",
    "        W_bar = W_reshaped / sigma\n",
    "        #reshape weight tensor\n",
    "        if training in {0, False}:\n",
    "            W_bar = K.reshape(W_bar, W_shape)\n",
    "        else:\n",
    "            with tf.control_dependencies([self.u.assign(_u)]):\n",
    "                W_bar = K.reshape(W_bar, W_shape)\n",
    "                \n",
    "        outputs = K.conv2d(\n",
    "                inputs,\n",
    "                W_bar,\n",
    "                strides=self.strides,\n",
    "                padding=self.padding,\n",
    "                data_format=self.data_format,\n",
    "                dilation_rate=self.dilation_rate)\n",
    "        if self.use_bias:\n",
    "            outputs = K.bias_add(\n",
    "                outputs,\n",
    "                self.bias,\n",
    "                data_format=self.data_format)\n",
    "        if self.activation is not None:\n",
    "            return self.activation(outputs)\n",
    "        return outputs\n",
    "\n",
    "    \n",
    "\n",
    "class ConvSN2DTranspose(Conv2DTranspose):\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if len(input_shape) != 4:\n",
    "            raise ValueError('Inputs should have rank ' +\n",
    "                             str(4) +\n",
    "                             '; Received input shape:', str(input_shape))\n",
    "        if self.data_format == 'channels_first':\n",
    "            channel_axis = 1\n",
    "        else:\n",
    "            channel_axis = -1\n",
    "        if input_shape[channel_axis] is None:\n",
    "            raise ValueError('The channel dimension of the inputs '\n",
    "                             'should be defined. Found `None`.')\n",
    "        input_dim = input_shape[channel_axis]\n",
    "        kernel_shape = self.kernel_size + (self.filters, input_dim)\n",
    "\n",
    "        self.kernel = self.add_weight(shape=kernel_shape,\n",
    "                                      initializer=self.kernel_initializer,\n",
    "                                      name='kernel',\n",
    "                                      regularizer=self.kernel_regularizer,\n",
    "                                      constraint=self.kernel_constraint)\n",
    "        if self.use_bias:\n",
    "            self.bias = self.add_weight(shape=(self.filters,),\n",
    "                                        initializer=self.bias_initializer,\n",
    "                                        name='bias',\n",
    "                                        regularizer=self.bias_regularizer,\n",
    "                                        constraint=self.bias_constraint)\n",
    "        else:\n",
    "            self.bias = None\n",
    "            \n",
    "        self.u = self.add_weight(shape=tuple([1, self.filters]),\n",
    "                        initializer=initializers.RandomNormal(0, 1),\n",
    "                        name='sn',\n",
    "                        trainable=False)\n",
    "        \n",
    "        # Set input spec.\n",
    "        self.input_spec = InputSpec(ndim=4, axes={channel_axis: input_dim})\n",
    "        self.built = True  \n",
    "    \n",
    "    def call(self, inputs):\n",
    "        input_shape = K.shape(inputs)\n",
    "        batch_size = input_shape[0]\n",
    "        if self.data_format == 'channels_first':\n",
    "            h_axis, w_axis = 2, 3\n",
    "        else:\n",
    "            h_axis, w_axis = 1, 2\n",
    "\n",
    "        height, width = input_shape[h_axis], input_shape[w_axis]\n",
    "        kernel_h, kernel_w = self.kernel_size\n",
    "        stride_h, stride_w = self.strides\n",
    "        if self.output_padding is None:\n",
    "            out_pad_h = out_pad_w = None\n",
    "        else:\n",
    "            out_pad_h, out_pad_w = self.output_padding\n",
    "\n",
    "        # Infer the dynamic output shape:\n",
    "        out_height = conv_utils.deconv_length(dim_size = height,\n",
    "                                                    kernel_size = kernel_h,\n",
    "                                                    padding=self.padding,\n",
    "                                                    output_padding=out_pad_h,\n",
    "                                                    stride_size=stride_h,\n",
    "                                                    dilation=self.dilation_rate[0])\n",
    "        out_width = conv_utils.deconv_length(dim_size = width,\n",
    "                                                    kernel_size = kernel_w,\n",
    "                                                    padding=self.padding,\n",
    "                                                    output_padding=out_pad_w,\n",
    "                                                    stride_size=stride_w,\n",
    "                                                    dilation=self.dilation_rate[1])\n",
    "        if self.data_format == 'channels_first':\n",
    "            output_shape = (batch_size, self.filters, out_height, out_width)\n",
    "        else:\n",
    "            output_shape = (batch_size, out_height, out_width, self.filters)\n",
    "\n",
    "        output_shape_tensor = array_ops.stack(output_shape)   \n",
    "        #Spectral Normalization    \n",
    "        def _l2normalize(v, eps=1e-12):\n",
    "            return v / (K.sum(v ** 2) ** 0.5 + eps)\n",
    "        def power_iteration(W, u):\n",
    "            #Accroding the paper, we only need to do power iteration one time.\n",
    "            _u = u\n",
    "            _v = _l2normalize(K.dot(_u, K.transpose(W)))\n",
    "            _u = _l2normalize(K.dot(_v, W))\n",
    "            return _u, _v\n",
    "        W_shape = self.kernel.shape.as_list()\n",
    "        #Flatten the Tensor\n",
    "        W_reshaped = K.reshape(self.kernel, [-1, W_shape[-2]])\n",
    "        _u, _v = power_iteration(W_reshaped, self.u)\n",
    "        #Calculate Sigma\n",
    "        sigma=K.dot(_v, W_reshaped)\n",
    "        sigma=K.dot(sigma, K.transpose(_u))\n",
    "        #normalize it\n",
    "        W_bar = W_reshaped / sigma\n",
    "        #reshape weight tensor\n",
    "        if training in {0, False}:\n",
    "            W_bar = K.reshape(W_bar, W_shape)\n",
    "        else:\n",
    "            with tf.control_dependencies([self.u.assign(_u)]):\n",
    "                W_bar = K.reshape(W_bar, W_shape)\n",
    "        self.kernel = W_bar\n",
    "        \n",
    "        outputs = K.conv2d_transpose(\n",
    "            inputs,\n",
    "            self.kernel,\n",
    "            output_shape_tensor,\n",
    "            self.strides,\n",
    "            padding=self.padding,\n",
    "            data_format=self.data_format)\n",
    "\n",
    "        if self.use_bias:\n",
    "            outputs = K.bias_add(\n",
    "                outputs,\n",
    "                self.bias,\n",
    "                data_format=self.data_format)\n",
    "\n",
    "        if self.activation is not None:\n",
    "            return self.activation(outputs)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "\n",
    "class SelfAttentionGamma(Layer):\n",
    "\n",
    "    def __init__(self,\n",
    "                 **kwargs):\n",
    "        super(SelfAttentionGamma, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        self.gamma = self.add_weight(shape=[1],\n",
    "                                         name='gamma',\n",
    "                                         initializer='zeros')\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        # print(inputs[1].shape.as_list())\n",
    "        # print(inputs[0].shape.as_list())\n",
    "        return self.gamma*K.reshape(inputs[1], shape = K.shape(inputs[0])) + inputs[0]\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "        }\n",
    "        base_config = super(SelfAttentionGamma, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        return input_shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load inception network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inception = InceptionV3(include_top=False, pooling='avg', input_shape=(299, 299, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currdir = 'C:\\\\Users\\\\parit\\\\Documents\\\\CycleGAN\\\\test\\\\'\n",
    "datadir = 'C:\\\\Users\\\\parit\\\\Documents\\\\CycleGAN\\\\datasets\\\\cezanne2photo\\\\'\n",
    "Disc_learningrate = 2e-4\n",
    "Gen_learningrate = 2e-4\n",
    "batch_size = 1\n",
    "LAMBDACYCLE = 10\n",
    "LAMBDAID = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation of activations from inception network for FID calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FID_BATCH_SIZE = 1\n",
    "def scale_images(images, new_shape):\n",
    "    images_list = list()\n",
    "    for image in images:\n",
    "        # resize with nearest neighbor interpolation\n",
    "        new_image = resize(image, new_shape, 0)\n",
    "        # store\n",
    "        images_list.append(new_image)\n",
    "    return asarray(images_list)\n",
    "\n",
    "def inception_activations(images):\n",
    "    size = 299\n",
    "    images = images.astype('float32')\n",
    "    images = scale_images(images, (299,299,3))\n",
    "    images = preprocess_input(images)\n",
    "    activations = inception.predict(images)\n",
    "    return activations\n",
    "## Batched FID because of my memory constraints\n",
    "def get_inception_activations(inps):\n",
    "    n_batches = int(np.ceil(float(inps.shape[0]) / FID_BATCH_SIZE))\n",
    "    act = np.zeros([inps.shape[0], 2048], dtype = np.float32)\n",
    "    for i in range(n_batches):\n",
    "        inp = inps[i * FID_BATCH_SIZE : (i + 1) * FID_BATCH_SIZE]\n",
    "        act[i * FID_BATCH_SIZE : i * FID_BATCH_SIZE + min(FID_BATCH_SIZE, inp.shape[0])] = inception_activations(inp)\n",
    "    return act"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation of FID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fidCalculate(g_func, testB, test_mean, test_sigma):\n",
    "    X_out = g_func.predict(testB)\n",
    "    X_out = (X_out + 1.) * 127.5\n",
    "    # print(X_out.shape)\n",
    "    f2 = get_inception_activations(X_out)\n",
    "    mean2, sigma2 = f2.mean(axis=0), np.cov(f2, rowvar=False)\n",
    "    sum_sq_diff = np.sum((test_mean - mean2)**2)\n",
    "    cov_mean = sqrtm(test_sigma.dot(sigma2))\n",
    "    if np.iscomplexobj(cov_mean):\n",
    "        cov_mean = cov_mean.real\n",
    "    fid = sum_sq_diff + np.trace(test_sigma + sigma2 - 2.0*cov_mean)\n",
    "    print(fid)\n",
    "    with open(currdir + \"logs/\"+\"FID_LOGS\" + \".txt\", \"a\") as f:\n",
    "        f.write(str(fid) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_models(step, g_model_AtoB, g_model_BtoA, d_model_A, d_model_B):\n",
    "\n",
    "    filename1 = currdir + \"models\\\\\" + 'g_model_AtoB_weights_%06d.h5' % (step+1)\n",
    "    g_model_AtoB.save_weights(filename1)\n",
    "    \n",
    "    filename2 = currdir + \"models\\\\\" + 'g_model_BtoA_weights_%06d.h5' % (step+1)\n",
    "    g_model_BtoA.save_weights(filename2)\n",
    "    \n",
    "    filename3 = currdir + \"models\\\\\" + 'd_model_A_weights_%06d.h5' % (step+1)\n",
    "    d_model_A.save_weights(filename3)\n",
    "    \n",
    "    filename4 =  currdir + \"models\\\\\" + 'd_model_B_weights_%06d.h5' % (step+1)\n",
    "    d_model_B.save_weights(filename4)\n",
    "    print('>Saved: models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading images and preprocessing(Random cropping and flipping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageprocess(img_path):   \n",
    "    img = image.load_img(img_path)\n",
    "    img = img.resize((143, 143), Image.BILINEAR) # To perform random cropping of size 15\n",
    "    img_arr = image.img_to_array(img)\n",
    "    img_norm = np.array(img_arr)/255*2-1\n",
    "    h1 = (143 - 128)//2\n",
    "    h2 = (143 + 128)//2\n",
    "    shift = randint(0,h1)\n",
    "    h1 = h1 - shift\n",
    "    h2 = h2 - shift\n",
    "    w1 = h1\n",
    "    w2 = h2\n",
    "    img_cropped = img_norm[h1:h2,w1:w2,:]\n",
    "    flip = randint(0,1)\n",
    "    if flip:\n",
    "        img_cropped = img_cropped[:,::-1]\n",
    "    return img_cropped\n",
    "\n",
    "def loadimage(path):\n",
    "    train_A_paths = glob.glob(path +  \"trainA/*.jpg\")\n",
    "    train_B_paths = glob.glob(path +  \"trainB/*.jpg\")\n",
    "    test_A_paths = glob.glob(path +  \"testA/*.jpg\")\n",
    "    test_B_paths = glob.glob(path +  \"testB/*.jpg\")\n",
    "    \n",
    "    data = []\n",
    "    for img_path in train_A_paths:\n",
    "        data.append(imageprocess(img_path))\n",
    "    train_A = np.float32(data)\n",
    "    print(train_A.shape)\n",
    "    del data\n",
    "#     print(train_A[0])\n",
    "    data = []\n",
    "    for img_path in train_B_paths:\n",
    "        data.append(imageprocess(img_path))\n",
    "    train_B = np.float32(data)\n",
    "    del data\n",
    "    \n",
    "    data = []\n",
    "    for img_path in test_A_paths:\n",
    "        data.append(imageprocess(img_path))\n",
    "    test_A = np.float32(data)\n",
    "    del data\n",
    "    \n",
    "    data = []\n",
    "    for img_path in test_B_paths:\n",
    "        data.append(imageprocess(img_path))\n",
    "    test_B = np.float32(data)\n",
    "    del data\n",
    "    \n",
    "    return train_A, train_B, test_A, test_B\n",
    "#     return train_A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_A, train_B, test_A, test_B = loadimage(datadir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate mean and sigma for A domain(artistic) images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid_pre = vstack(((train_A + 1.)*127.5, (test_A + 1.)*127.5))\n",
    "f1 = get_inception_activations(fid_pre)\n",
    "test_mean, test_sigma = f1.mean(axis=0), np.cov(f1, rowvar=False)\n",
    "del fid_pre, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "used for selfattention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mult1(x):\n",
    "    x1 = x[0]\n",
    "    x2 = x[1]\n",
    "    x3 = K.permute_dimensions(x[1],pattern=(0,2,1))\n",
    "    x4 = K.batch_dot(x1, x3, axes=(2,1))\n",
    "    return x4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discriminator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define the discriminator model\n",
    "def define_discriminator(image_shape = (128, 128, 3)):\n",
    "    \n",
    "    init = 'glorot_uniform'\n",
    "   \n",
    "    in_image = Input(shape=image_shape)\n",
    "   \n",
    "    d = ConvSN2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(in_image)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    \n",
    "    d = ConvSN2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "#     d = BatchNormalization(momentum=0.9, epsilon=1.01e-5)(d, training=1)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    \n",
    "    SAop_f = ConvSN2D(128//8, kernel_size=1, strides=1,kernel_initializer='glorot_uniform', padding='same', activation=None)(d)\n",
    "    # print(SAop_f.shape.as_list())\n",
    "    SAop_f_re = Lambda(lambda x:K.reshape(x, shape = (K.shape(x)[0], -1,K.shape(x)[3])))(SAop_f)\n",
    "    # print(SAop_f_re.shape.as_list())\n",
    "    SAop_g = ConvSN2D(128//8, kernel_size=1, strides=1,kernel_initializer='glorot_uniform', padding='same', activation=None)(d)\n",
    "    SAop_g_re = Lambda(lambda x:K.reshape(x, shape = (K.shape(x)[0], K.shape(x)[1]*K.shape(x)[2],K.shape(x)[-1])))(SAop_g)\n",
    "    SAop_h = ConvSN2D(128, kernel_size=1, strides=1,kernel_initializer='glorot_uniform', padding='same', activation=None)(d)\n",
    "    SAop_h_re = Lambda(lambda x:K.reshape(x, shape = (K.shape(x)[0], K.shape(x)[1]*K.shape(x)[2],K.shape(x)[-1])))(SAop_h)\n",
    "    mult = Lambda(lambda x:mult1(x))([SAop_g_re, SAop_f_re])\n",
    "    # print(mult.shape.as_list())\n",
    "    attnmap = Softmax(axis=-1)(mult)\n",
    "    # print(attnmap.shape.as_list())\n",
    "    SAop = Lambda(lambda x:K.batch_dot(x[0], x[1], axes=(2, 1)))([attnmap, SAop_h_re])\n",
    "    # print(SAop.shape.as_list())\n",
    "    d = SelfAttentionGamma()([d, SAop])    \n",
    "    \n",
    "    \n",
    "    \n",
    "    d = ConvSN2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "#     d = BatchNormalization(momentum=0.9, epsilon=1.01e-5)(d, training=1)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    \n",
    "    d = ConvSN2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "#     d = BatchNormalization(momentum=0.9, epsilon=1.01e-5)(d, training=1)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    \n",
    "    # second last output layer\n",
    "    d = Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)\n",
    "    d = BatchNormalization(momentum=0.9, epsilon=1.01e-5)(d, training=1)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # patch output\n",
    "    \n",
    "    patch_out = ConvSN2D(1, (4,4), padding='same', kernel_initializer=init)(d)\n",
    "    # define model\n",
    "    model = Model(in_image, patch_out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resnet Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_block(n_filters, input_layer):\n",
    "    \n",
    "    init = 'glorot_uniform'\n",
    "    \n",
    "    g = ConvSN2D(n_filters, (3,3), padding='same', kernel_initializer=init)(input_layer)\n",
    "    # g = BatchNormalization(momentum=0.9, epsilon=1.01e-5)(g, training=1)\n",
    "    g = Activation('relu')(g)\n",
    "    \n",
    "    g = ConvSN2D(n_filters, (3,3), padding='same', kernel_initializer=init)(g)\n",
    "    # g = BatchNormalization(momentum=0.9, epsilon=1.01e-5)(g, training=1)\n",
    "    \n",
    "    g = Add()([g, input_layer])\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_generator(image_shape=(128,128,3), n_resnet=6):\n",
    "    # weight initialization\n",
    "    init = 'glorot_uniform'\n",
    "    # image input\n",
    "    in_image = Input(shape=image_shape)\n",
    "    \n",
    "    g = ConvSN2D(64, (7,7), padding='same', kernel_initializer=init)(in_image)\n",
    "    # g = BatchNormalization(momentum=0.9, epsilon=1.01e-5)(g, training=1)\n",
    "    g = Activation('relu')(g)\n",
    "    \n",
    "    g = ConvSN2D(128, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n",
    "    # g = BatchNormalization(momentum=0.9, epsilon=1.01e-5)(g, training=1)\n",
    "    g = Activation('relu')(g)\n",
    "    \n",
    "    g = ConvSN2D(256, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n",
    "    # g = BatchNormalization(momentum=0.9, epsilon=1.01e-5)(g, training=1)\n",
    "    g = Activation('relu')(g)\n",
    "    \n",
    "    for _ in range(n_resnet):\n",
    "        g = resnet_block(256, g)\n",
    "    \n",
    "    g = ConvSN2DTranspose(128, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n",
    "    # g = BatchNormalization(momentum=0.9, epsilon=1.01e-5)(g, training=1)\n",
    "    g = Activation('relu')(g)\n",
    "    \n",
    "    g = ConvSN2DTranspose(64, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n",
    "    # g = BatchNormalization(momentum=0.9, epsilon=1.01e-5)(g, training=1)\n",
    "    g = Activation('relu')(g)\n",
    "    \n",
    "    g = ConvSN2D(3, (7,7), padding='same', kernel_initializer=init)(g)\n",
    "    # g = BatchNormalization(momentum=0.9, epsilon=1.01e-5)(g, training=1)\n",
    "    out_image = Activation('tanh')(g)\n",
    "    # define model\n",
    "    model = Model(in_image, out_image)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Disc_A = define_discriminator(image_shape=(128,128,3))\n",
    "Disc_B = define_discriminator(image_shape=(128,128,3))\n",
    "Disc_A.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gen_AtoB = define_generator(image_shape=(128,128,3))\n",
    "Gen_BtoA = define_generator(image_shape=(128,128,3))\n",
    "Gen_AtoB.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Loss Functions : Generator Loss, Discriminator Loss, Cycle Loss, Identity Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = lambda output, target : K.mean(K.abs(K.square(output-target)))\n",
    "\n",
    "fake_pool_a = K.placeholder(shape=(None, 128, 128, 3))\n",
    "fake_pool_b = K.placeholder(shape=(None, 128, 128, 3))\n",
    "\n",
    "real_A = Gen_AtoB.inputs[0]\n",
    "real_B = Gen_BtoA.inputs[0]\n",
    "\n",
    "fake_B = Gen_AtoB.outputs[0]\n",
    "fake_A = Gen_BtoA.outputs[0]\n",
    "\n",
    "rec_A = Gen_BtoA([fake_B])\n",
    "rec_B = Gen_AtoB([fake_A])\n",
    "\n",
    "cycle_ABA = K.function([real_A], [fake_B, rec_A])\n",
    "cycle_BAB = K.function([real_B], [fake_A, rec_B])\n",
    "\n",
    "\n",
    "Disc_op_real_A = Disc_A([real_A])\n",
    "Disc_op_fake_A = Disc_A([fake_A])\n",
    "Disc_op_fakepool_A = Disc_A([fake_pool_a])\n",
    "\n",
    "Disc_A_real_loss = loss_fn(Disc_op_real_A, K.ones_like(Disc_op_real_A))\n",
    "Disc_A_fake_loss = loss_fn(Disc_op_fakepool_A, K.zeros_like(Disc_op_fakepool_A))\n",
    "\n",
    "Disc_A_loss = Disc_A_real_loss + Disc_A_fake_loss\n",
    "\n",
    "Disc_op_real_B = Disc_B([real_B])\n",
    "Disc_op_fake_B = Disc_B([fake_B])\n",
    "Disc_op_fakepool_B = Disc_B([fake_pool_b])\n",
    "\n",
    "Disc_B_real_loss = loss_fn(Disc_op_real_B, K.ones_like(Disc_op_real_B))\n",
    "Disc_B_fake_loss = loss_fn(Disc_op_fakepool_B, K.zeros_like(Disc_op_fakepool_B))\n",
    "\n",
    "Disc_B_loss = Disc_B_real_loss + Disc_B_fake_loss\n",
    "\n",
    "Gen_BtoA_loss = loss_fn(Disc_op_fake_A, K.ones_like(Disc_op_fake_A))\n",
    "Gen_AtoB_loss = loss_fn(Disc_op_fake_B, K.ones_like(Disc_op_fake_B))\n",
    "\n",
    "loss_cycle_A = K.mean(K.abs(rec_A-real_A))\n",
    "loss_cycle_B = K.mean(K.abs(rec_B-real_B))\n",
    "\n",
    "tot_loss_cycle = loss_cycle_A + loss_cycle_B\n",
    "\n",
    "id_A = Gen_BtoA([real_A])\n",
    "loss_id_A = K.mean(K.abs(id_A - real_A))\n",
    "\n",
    "id_B = Gen_AtoB([real_B])\n",
    "loss_id_B = K.mean(K.abs(id_B - real_B))\n",
    "\n",
    "tot_loss_id = loss_id_A + loss_id_B\n",
    "\n",
    "tot_loss_D = Disc_A_loss + Disc_B_loss\n",
    "\n",
    "tot_loss_G = Gen_BtoA_loss + Gen_AtoB_loss + LAMBDACYCLE*tot_loss_cycle + LAMBDAID*tot_loss_id\n",
    "\n",
    "weightsD = Disc_A.trainable_weights + Disc_B.trainable_weights\n",
    "weightsG = Gen_AtoB.trainable_weights + Gen_BtoA.trainable_weights\n",
    "\n",
    "training_updates_disc = Adam(lr=Disc_learningrate, beta_1=0.5).get_updates(weightsD,[],tot_loss_D)\n",
    "Disc_train = K.function([real_A, real_B, fake_pool_a, fake_pool_b],[Disc_A_loss, Disc_B_loss], training_updates_disc)\n",
    "\n",
    "training_updates_gen = Adam(lr=Gen_learningrate, beta_1=0.5).get_updates(weightsG,[], tot_loss_G)\n",
    "Gen_train = K.function([real_A, real_B, fake_pool_a, fake_pool_b], [Gen_BtoA_loss, Gen_AtoB_loss, tot_loss_cycle, tot_loss_id], training_updates_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from io import BytesIO\n",
    "byte_io = BytesIO()\n",
    "def display_image(X, rows=1, iteration=1, sv = False):\n",
    "    assert X.shape[0]%rows == 0\n",
    "    int_X = ((X+1.)*127.5).clip(0,255).astype('uint8')\n",
    "    int_X = int_X.reshape(rows, -1, 128, 128,3).swapaxes(1,2).reshape(rows*128,-1, 3)\n",
    "    img = Image.fromarray(int_X)\n",
    "    display(img)\n",
    "    if sv:\n",
    "        img.save(currdir + \"images/\" + \"{}.png\".format(iteration),\"PNG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_image(A,B, iteration = 0, sv = False):\n",
    "    assert A.shape==B.shape\n",
    "    def G(fn_generate, X, Y):\n",
    "        r = np.array([fn_generate([X[i:i+1]]) for i in range(X.shape[0])])\n",
    "#         print(r.shape)\n",
    "        return r.swapaxes(0,1)[:,:,0]        \n",
    "    rA = G(cycle_ABA, A, B)\n",
    "    rB = G(cycle_BAB, B, A)\n",
    "    arr = np.concatenate([A,B,rA[0],rB[0],rA[1],rB[1]])\n",
    "    display_image(arr, 3, iteration, sv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from IPython.display import clear_output\n",
    "t0 = time.time()\n",
    "MAXEPOCHS = 100\n",
    "steps = 0\n",
    "epoch = 0\n",
    "localepoch1 = 0\n",
    "localepoch2 = 0\n",
    "err_Gen_BtoA = 0\n",
    "err_Gen_AtoB = 0\n",
    "err_Disc_A = 0\n",
    "err_Disc_B = 0\n",
    "err_cycle = 0\n",
    "err_id = 0\n",
    "display_iters = 50\n",
    "fid_freq = 1000\n",
    "save_freq = 7000\n",
    "save_image_iters = 3000\n",
    "j = 0\n",
    "i = 0\n",
    "\n",
    "\n",
    "fake_A_pool = []\n",
    "fake_B_pool = []\n",
    "\n",
    "while epoch < MAXEPOCHS:   \n",
    "    \n",
    "    if j+batch_size > len(train_A):\n",
    "        j = 0\n",
    "        localepoch1 += 1\n",
    "        np.random.shuffle(train_A)\n",
    "    A = train_A[j:j+batch_size]\n",
    "    j += batch_size\n",
    "\n",
    "    if i+batch_size > len(train_B):\n",
    "        i = 0\n",
    "        localepoch2 += 1\n",
    "        np.random.shuffle(train_B)\n",
    "    B = train_B[i:i+batch_size]\n",
    "    i += batch_size\n",
    "    \n",
    "    epoch = min(localepoch1, localepoch2)\n",
    "\n",
    "    tmp_fake_A = Gen_BtoA.predict(B)\n",
    "    tmp_fake_B = Gen_AtoB.predict(A) \n",
    "\n",
    "    tmp_A = []\n",
    "    tmp_B = []\n",
    "    \n",
    "    for img in tmp_fake_A:\n",
    "        if len(fake_A_pool) < 50:  ## pool size of 50\n",
    "            fake_A_pool.append(img)\n",
    "            tmp_A.append(img)\n",
    "        else:\n",
    "            p = np.random.uniform(0, 1)\n",
    "            if p > 0.5:\n",
    "                random_id = randint(0, 49)\n",
    "                tmp = np.copy(fake_A_pool[random_id])\n",
    "                fake_A_pool[random_id] = img\n",
    "                tmp_A.append(tmp)\n",
    "            else:\n",
    "                tmp_A.append(img)\n",
    "                \n",
    "    for img in tmp_fake_B:\n",
    "        if len(fake_B_pool) < 50:\n",
    "            fake_B_pool.append(img)\n",
    "            tmp_B.append(img)\n",
    "        else:\n",
    "            p = np.random.uniform(0, 1)\n",
    "            if p > 0.5:\n",
    "                random_id = randint(0, 49)\n",
    "                tmp = np.copy(fake_B_pool[random_id])\n",
    "                fake_B_pool[random_id] = img\n",
    "                tmp_B.append(tmp)\n",
    "            else:\n",
    "                tmp_B.append(img) \n",
    "    \n",
    "    pool_a = np.array(tmp_A)\n",
    "    pool_b = np.array(tmp_B)\n",
    "           \n",
    "    err_Disc_A, err_Disc_B = Disc_train([A, B, pool_a, pool_b])\n",
    "  \n",
    "    err_Gen_BtoA, err_Gen_AtoB, err_cycle, err_id = Gen_train([A, B, pool_a, pool_b])\n",
    "    steps+=1\n",
    "    \n",
    "    with open(currdir + \"logs/\" + \"losses_logs\" + \".txt\", \"a\") as f:\n",
    "        f.write(str(err_Disc_A) + '\\t' + str(err_Disc_B) + '\\t' + str(err_Gen_BtoA) + '\\t' + str(err_Gen_AtoB) + '\\t' +  str(err_cycle) + '\\t' + str(err_id) + '\\n')\n",
    "    print(\"err_Disc_A: {}\".format(err_Disc_A) + \" err_Disc_B: {}\".format(err_Disc_B) + \" err_Gen_BtoA: {}\".format(err_Gen_BtoA) + \" err_Gen_AtoB: {}\".format(err_Gen_AtoB))    \n",
    "        \n",
    "    \n",
    "    if steps%fid_freq == 0:\n",
    "        print(time.time()-t0)\n",
    "        print(\"Epoch-{}\".format(epoch))\n",
    "        print(\"err_Disc_A: {}\".format(err_Disc_A) + \" err_Disc_B: {}\".format(err_Disc_B) + \" err_Gen_BtoA: {}\".format(err_Gen_BtoA) + \" err_Gen_AtoB: {}\".format(err_Gen_AtoB))\n",
    "        idx = randint(0,len(test_B)-100)\n",
    "        fid_B_data = test_B[idx:idx+100]\n",
    "        fidCalculate(Gen_BtoA, fid_B_data, test_mean, test_sigma)      \n",
    "\n",
    "    if steps%display_iters==0:\n",
    "        clear_output()\n",
    "        \n",
    "        if j+4 > len(train_A):\n",
    "            j = 0\n",
    "            localepoch1 += 1\n",
    "            np.random.shuffle(train_A)\n",
    "        A = train_A[j:j+4]\n",
    "        j += 4\n",
    "\n",
    "        if i+4 > len(train_B):\n",
    "            i = 0\n",
    "            localepoch2 += 1\n",
    "            np.random.shuffle(train_B)\n",
    "        B = train_B[i:i+4]\n",
    "        i += 4        \n",
    "        \n",
    "        if(steps%save_image_iters == 0):\n",
    "            gen_image(A, B, steps, sv=True)\n",
    "        else:\n",
    "            gen_image(A,B, steps)\n",
    "    \n",
    "   \n",
    "    if steps%save_freq == 0:\n",
    "        save_models(steps, Gen_AtoB, Gen_BtoA, Disc_A, Disc_B)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = randint(0, len(train_B))\n",
    "B = train_B[idx:idx+1]\n",
    "def G(fn_generate, X):\n",
    "    r = np.array([fn_generate([X[i:i+1]]) for i in range(X.shape[0])])\n",
    "#         print(r.shape)\n",
    "    return r.swapaxes(0,1)[:,:,0]\n",
    "Gen_BtoA.load_weights('C:\\\\Users\\\\parit\\\\Documents\\\\CycleGAN\\\\CycleGANRestNetGenSN1SA\\\\cezanne\\\\finalweights\\\\' + 'g_model_BtoA_weights_010001.h5')\n",
    "Gen_AtoB.load_weights('C:\\\\Users\\\\parit\\\\Documents\\\\CycleGAN\\\\CycleGANRestNetGenSN1SA\\\\cezanne\\\\finalweights\\\\' + 'g_model_AtoB_weights_010001.h5')\n",
    "Disc_A.load_weights('C:\\\\Users\\\\parit\\\\Documents\\\\CycleGAN\\\\CycleGANRestNetGenSN1SA\\\\cezanne\\\\finalweights\\\\' + 'd_model_A_weights_010001.h5')\n",
    "Disc_B.load_weights('C:\\\\Users\\\\parit\\\\Documents\\\\CycleGAN\\\\CycleGANRestNetGenSN1SA\\\\cezanne\\\\finalweights\\\\' + 'd_model_B_weights_010001.h5')    \n",
    "r_cezanne = G(cycle_BAB, B)\n",
    "arr = np.concatenate([B, r_cezanne[0]])\n",
    "display_image(arr, 1)\n",
    "\n",
    "idx_fid = randint(0,len(test_B)-100)\n",
    "fid_B_data = test_B[idx_fid:idx_fid+100]\n",
    "print(\"FID:\")\n",
    "fidCalculate(Gen_BtoA, fid_B_data, test_mean, test_sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this cell for generating all artistic images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = randint(0, len(train_B))\n",
    "B = train_B[idx:idx+1]\n",
    "\n",
    "        \n",
    "def G(fn_generate, X):\n",
    "    r = np.array([fn_generate([X[i:i+1]]) for i in range(X.shape[0])])\n",
    "    return r.swapaxes(0,1)[:,:,0]\n",
    "\n",
    "Gen_BtoA.load_weights('C:\\\\Users\\\\parit\\\\Documents\\\\CycleGAN\\\\CycleGANRestNetGenSN1SA\\\\ukiyoe\\\\finalweights\\\\' + 'g_model_BtoA_weights_069001.h5')\n",
    "Gen_AtoB.load_weights('C:\\\\Users\\\\parit\\\\Documents\\\\CycleGAN\\\\CycleGANRestNetGenSN1SA\\\\ukiyoe\\\\finalweights\\\\' + 'g_model_AtoB_weights_069001.h5')\n",
    "Disc_A.load_weights('C:\\\\Users\\\\parit\\\\Documents\\\\CycleGAN\\\\CycleGANRestNetGenSN1SA\\\\ukiyoe\\\\finalweights\\\\' + 'd_model_A_weights_069001.h5')\n",
    "Disc_B.load_weights('C:\\\\Users\\\\parit\\\\Documents\\\\CycleGAN\\\\CycleGANRestNetGenSN1SA\\\\ukiyoe\\\\finalweights\\\\' + 'd_model_B_weights_069001.h5')\n",
    "r_ukiyoe = G(cycle_BAB, B)\n",
    "\n",
    "Gen_BtoA.load_weights('C:\\\\Users\\\\parit\\\\Documents\\\\CycleGAN\\\\CycleGANRestNetGenSN1SA\\\\vangogh\\\\finalweights\\\\' + 'g_model_BtoA_weights_024001.h5')\n",
    "Gen_AtoB.load_weights('C:\\\\Users\\\\parit\\\\Documents\\\\CycleGAN\\\\CycleGANRestNetGenSN1SA\\\\vangogh\\\\finalweights\\\\' + 'g_model_AtoB_weights_024001.h5')\n",
    "Disc_A.load_weights('C:\\\\Users\\\\parit\\\\Documents\\\\CycleGAN\\\\CycleGANRestNetGenSN1SA\\\\vangogh\\\\finalweights\\\\' + 'd_model_A_weights_024001.h5')\n",
    "Disc_B.load_weights('C:\\\\Users\\\\parit\\\\Documents\\\\CycleGAN\\\\CycleGANRestNetGenSN1SA\\\\vangogh\\\\finalweights\\\\' + 'd_model_B_weights_024001.h5')    \n",
    "r_vangogh = G(cycle_BAB, B)\n",
    "\n",
    "Gen_BtoA.load_weights('C:\\\\Users\\\\parit\\\\Documents\\\\CycleGAN\\\\CycleGANRestNetGenSN1SA\\\\monet\\\\finalweights\\\\' + 'g_model_BtoA_weights_041202.h5')\n",
    "Gen_AtoB.load_weights('C:\\\\Users\\\\parit\\\\Documents\\\\CycleGAN\\\\CycleGANRestNetGenSN1SA\\\\monet\\\\finalweights\\\\' + 'g_model_AtoB_weights_041202.h5')\n",
    "Disc_A.load_weights('C:\\\\Users\\\\parit\\\\Documents\\\\CycleGAN\\\\CycleGANRestNetGenSN1SA\\\\monet\\\\finalweights\\\\' + 'd_model_A_weights_041202.h5')\n",
    "Disc_B.load_weights('C:\\\\Users\\\\parit\\\\Documents\\\\CycleGAN\\\\CycleGANRestNetGenSN1SA\\\\monet\\\\finalweights\\\\' + 'd_model_B_weights_041202.h5')    \n",
    "r_monet = G(cycle_BAB, B)\n",
    "\n",
    "Gen_BtoA.load_weights('C:\\\\Users\\\\parit\\\\Documents\\\\CycleGAN\\\\CycleGANRestNetGenSN1SA\\\\cezanne\\\\finalweights\\\\' + 'g_model_BtoA_weights_010001.h5')\n",
    "Gen_AtoB.load_weights('C:\\\\Users\\\\parit\\\\Documents\\\\CycleGAN\\\\CycleGANRestNetGenSN1SA\\\\cezanne\\\\finalweights\\\\' + 'g_model_AtoB_weights_010001.h5')\n",
    "Disc_A.load_weights('C:\\\\Users\\\\parit\\\\Documents\\\\CycleGAN\\\\CycleGANRestNetGenSN1SA\\\\cezanne\\\\finalweights\\\\' + 'd_model_A_weights_010001.h5')\n",
    "Disc_B.load_weights('C:\\\\Users\\\\parit\\\\Documents\\\\CycleGAN\\\\CycleGANRestNetGenSN1SA\\\\cezanne\\\\finalweights\\\\' + 'd_model_B_weights_010001.h5')    \n",
    "r_cezanne = G(cycle_BAB, B)\n",
    "\n",
    "arr = np.concatenate([B,r_ukiyoe[0], r_vangogh[0], r_monet[0], r_cezanne[0]])\n",
    "print(\"   real image     Ukiyoe image     Vangogh Image     Monet image      Cezanne Image\")                        \n",
    "display_image(arr, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References: https://github.com/tjwei/GANotebooks/blob/master/CycleGAN-keras.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
